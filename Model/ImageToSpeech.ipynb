{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "i7QMcjUQThBk"
      },
      "outputs": [],
      "source": [
        "pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain-community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YzWtO_vATkkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oe2xadAGTmp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas==2.2.2 networkx==3.2\n"
      ],
      "metadata": {
        "id": "9lRKebwT-LrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install TTS\n"
      ],
      "metadata": {
        "id": "w6ADoz0NkRFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bitsandbytes"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3BR-vVM7ToVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade numpy transformers\n"
      ],
      "metadata": {
        "id": "mKC0pyo90JIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade torch\n"
      ],
      "metadata": {
        "id": "A_g13VUk0NzC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "import torch\n",
        "import IPython.display as ipd\n",
        "from langchain import HuggingFacePipeline, LLMChain\n",
        "from langchain.prompts import PromptTemplate,StringPromptTemplate\n",
        "from transformers import pipeline as tts_pipeline\n",
        "from IPython.display import Audio\n"
      ],
      "metadata": {
        "id": "_ggB75e58xkr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "access_token = \" \"#insert your hugging face access token here\n",
        "import os\n",
        "HUGGINGFACE_API_TOKEN = os.getenv(\" \")#insert your hugging face access token here\n",
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "import torch\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")"
      ],
      "metadata": {
        "id": "B2U1-eOnTqBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        token=access_token,\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "EpQS0bRxTsWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    max_new_tokens=500,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\",\n",
        "    temperature=1.0,  # Controls creativity. Higher value = more random.\n",
        "    top_k=50,         # Considers top 50 tokens for the next word.\n",
        "    top_p=0.9         # Nucleus sampling. Picks from smallest set with 90% probability mass.\n",
        ")\n"
      ],
      "metadata": {
        "id": "TukSejAb_esk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "# Function to generate text from an image\n",
        "def generate_text_from_image(url: str) -> str:\n",
        "    image_to_text = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
        "    generated_text = image_to_text(url)[0][\"generated_text\"]\n",
        "    return generated_text\n",
        "\n"
      ],
      "metadata": {
        "id": "4KfBmdAZ7EBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Function that generates a random story based on image text and optional user input\n",
        "def generate_story(image_url: str, user_input: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Generates a complete story from the image and optional user input.\n",
        "    The story length is now flexible and won't be cut off.\n",
        "\n",
        "    :param image_url: URL of the image\n",
        "    :param user_input: Optional input to enhance the story\n",
        "    :return: Generated story\n",
        "    \"\"\"\n",
        "    # Generate text from the image\n",
        "    image_text = generate_text_from_image(image_url)\n",
        "\n",
        "   # Add a random twist or element to the prompt to ensure variability\n",
        "    random_twist = random.choice([\n",
        "        \"a new friend is discovered\",\n",
        "        \"a hidden treasure is found\",\n",
        "        \"the characters meet a helpful animal\",\n",
        "        \"everyone learns a surprising dance move\",\n",
        "        \"a magical rainbow appears\",\n",
        "        \"a funny creature joins the adventure\",\n",
        "        \"a friendly wizard grants a wish\",\n",
        "        \"they find a secret map leading to fun places\",\n",
        "        \"a magical garden grows around them\",\n",
        "        \"a playful wind brings floating bubbles\"\n",
        "    ])\n",
        "    # Define the prompt template based on whether user input is provided\n",
        "    if user_input:\n",
        "        template = f\"\"\"\n",
        "        You are a talented storyteller who creates a story from a simple narrative.\n",
        "        Create a unique and complete story using the following scenario. The story should have an unpredictable twist.\n",
        "\n",
        "        CONTEXT: {{scenario}}\n",
        "        USER INPUT: {{user_input}}\n",
        "        RANDOM TWIST: {random_twist}\n",
        "        STORY:\n",
        "        \"\"\"\n",
        "        input_variables = ['scenario', 'user_input']\n",
        "        prompt = PromptTemplate(template=template, input_variables=input_variables)\n",
        "        # Generate the story using both image text and user input\n",
        "        story = LLMChain(llm=llm, prompt=prompt, verbose=True)({\"scenario\": image_text, \"user_input\": user_input})['text']\n",
        "    else:\n",
        "        template = f\"\"\"\n",
        "        You are a talented storyteller who creates a story from a simple narrative.\n",
        "        Create a unique and complete story using the following scenario. The story should include an unpredictable twist.\n",
        "\n",
        "        CONTEXT: {{scenario}}\n",
        "        RANDOM TWIST: {random_twist}\n",
        "        STORY:\n",
        "        \"\"\"\n",
        "        input_variables = ['scenario']\n",
        "        prompt = PromptTemplate(template=template, input_variables=input_variables)\n",
        "        # Generate the story using only the image text\n",
        "        story = LLMChain(llm=llm, prompt=prompt, verbose=True)({\"scenario\": image_text})['text']\n",
        "\n",
        "    # Extract the generated story\n",
        "    story = story.split('STORY:')[-1].strip()\n",
        "\n",
        "    # Return the story\n",
        "    return story"
      ],
      "metadata": {
        "id": "PicbggK5-xaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "image_url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTK1-jnmxzUJLYT1XGcVC21gN8QC17ZjGZALA&s\"\n",
        "user_input = \" \"\n",
        "\n"
      ],
      "metadata": {
        "id": "bj3OObXBXntS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "\n",
        "image_url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTK1-jnmxzUJLYT1XGcVC21gN8QC17ZjGZALA&s\"\n",
        "\n",
        "# Fetch the image\n",
        "response = requests.get(image_url)\n",
        "image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
        "image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
        "\n",
        "if image is None:\n",
        "    print(\"Error: Failed to load image from URL!\")\n",
        "else:\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "pB9M9pAw4E9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate story\n",
        "import textwrap\n",
        "story = generate_story(image_url, user_input)\n",
        "width_story=textwrap.fill(story,width=100)\n",
        "print(\"Generated Story:\", width_story)\n",
        "\n"
      ],
      "metadata": {
        "id": "Vmuae1DNbqhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip install numpy==1.23.5\n"
      ],
      "metadata": {
        "id": "-zXYp-q88I2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall librosa -y\n",
        "!pip install librosa\n"
      ],
      "metadata": {
        "id": "qzfsNKspLllB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the Bark TTS pipeline\n",
        "pipe_tts = pipeline(\"text-to-speech\", model=\"suno/bark\")\n",
        "\n",
        "def generate_speech_from_story(story: str):\n",
        "    \"\"\"\n",
        "    Converts a generated story to speech using Hugging Face Bark TTS pipeline.\n",
        "\n",
        "    :param story: The generated story text\n",
        "    :return: Audio output\n",
        "    \"\"\"\n",
        "    # Generate audio from text\n",
        "    output = pipe_tts(story)\n",
        "\n",
        "    # Play the audio\n",
        "    return ipd.Audio(output[\"audio\"], rate=22050)\n",
        "\n",
        "# Example usage with an LLM-generated story\n",
        "#story = story\n",
        "\n",
        "# Generate speech\n",
        "audio_output = generate_speech_from_story(story)\n",
        "\n",
        "# Play the audio\n",
        "audio_output\n"
      ],
      "metadata": {
        "id": "87esRIJi67iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Function to generate speech from text\n",
        "def generate_speech_from_story(story: str):\n",
        "    \"\"\"\n",
        "    Converts a generated story to speech.\n",
        "\n",
        "    :param story: The generated story text\n",
        "    :return: Audio output\n",
        "    \"\"\"\n",
        "    # Create TTS pipeline\n",
        "    pipe_tts = tts_pipeline(\"text-to-speech\", model=\"suno/bark-small\")\n",
        "    output_audio = pipe_tts(story)\n",
        "\n",
        "    # Play the audio\n",
        "    return output_audio[\"audio\"]\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "WwatRadCXUhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import torch\n",
        "from TTS.api import TTS\n",
        "import IPython.display as ipd  # For playing audio in Jupyter\n",
        "\n",
        "# Load a TTS model (choose from Coqui TTS available models)\n",
        "tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\")  # Example model\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "o4TtMj_ilxj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Function to convert a story to speech\n",
        "def generate_speech_from_story(story):\n",
        "    \"\"\"\n",
        "    Converts a generated story to speech and plays the audio.\n",
        "\n",
        "    :param story_text: The generated story text\n",
        "    \"\"\"\n",
        "    output_path = \"output_story.wav\"\n",
        "\n",
        "    # Generate speech from the text and save to a file\n",
        "    tts.tts_to_file(text=story, file_path=output_path,max_decoder_steps=20000)\n",
        "\n",
        "    # Play the generated audio in Jupyter Notebook\n",
        "    return ipd.Audio(output_path, rate=22050)\n",
        "\n",
        "# Example: Using a generated story\n",
        "generated_story = story\n",
        "\n",
        "# Convert story to speech and play\n",
        "audio_output = generate_speech_from_story(generated_story)\n",
        "audio_output  # This will play the audio in Jupyter Notebook'''"
      ],
      "metadata": {
        "id": "baRi8uVp1sDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''from TTS.api import TTS\n",
        "\n",
        "# Create an instance of TTS first\n",
        "tts = TTS()\n",
        "\n",
        "# Now list available models\n",
        "print(tts.list_models())\n",
        "'''"
      ],
      "metadata": {
        "id": "S-_rDRv9tIZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate speech\n",
        "#audio_output = generate_speech_from_story(story)\n",
        "\n"
      ],
      "metadata": {
        "id": "AzRJNTfcbqee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the audio\n",
        "#Audio(audio_output, rate=22050)"
      ],
      "metadata": {
        "id": "NzLQPd-ibrKL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}